#!/usr/bin/env python3
"""
Agent Cross-Testing System
===========================
Each agent tests other agents to ensure complete system functionality.
This creates a comprehensive testing matrix where every agent validates others.
"""

import subprocess
import json
import sys
import os
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any

class AgentCrossTester:
    """Cross-testing system for all AI agents"""
    
    def __init__(self):
        self.agents = [
            # Development Pipeline
            ("ai-architect-agent", "Architecture and Design", ["system/design", "priority/P2"]),
            ("ai-developer-agent", "Code Implementation", ["development/feature", "priority/P2"]),
            ("ai-qa-agent", "Quality Assurance", ["qa/testing", "priority/P2"]),
            ("ai-devops-agent", "Deployment Operations", ["devops/deployment", "priority/P2"]),
            ("ai-manager-agent", "General Management", ["management/general", "priority/P2"]),
            
            # Business Operations
            ("ai-project-manager-agent", "Executive Oversight", ["management/strategic-planning", "priority/P1"]),
            ("ai-marketing-agent", "Marketing Operations", ["marketing/campaign", "priority/P2"]),
            ("ai-sales-agent", "Sales Operations", ["sales/lead", "priority/P2"]),
            ("ai-support-agent", "Customer Support", ["support/quality-assurance", "priority/P2"]),
            ("ai-customer-success-agent", "Customer Success", ["success/user-research", "priority/P2"]),
            ("ai-analytics-agent", "Analytics and Reporting", ["analytics/reporting", "priority/P2"]),
            ("ai-finance-agent", "Financial Operations", ["finance/analysis", "priority/P2"]),
            ("ai-operations-agent", "Infrastructure Operations", ["operations/monitoring", "priority/P1"]),
            ("ai-security-agent", "Security Operations", ["security/compliance", "priority/P1"])
        ]
        
        self.test_results = {}
        self.test_matrix = {}
        
    def create_test_issue(self, tester_agent: str, target_agent: str, labels: List[str]) -> Dict[str, Any]:
        """Create a test issue for cross-testing"""
        return {
            "number": f"TEST-{datetime.now().strftime('%H%M%S')}",
            "title": f"Cross-Test: {tester_agent} testing {target_agent}",
            "body": f"""## Automated Cross-Testing

**Tester Agent**: {tester_agent}
**Target Agent**: {target_agent}
**Test Time**: {datetime.now().isoformat()}

### Test Objectives:
1. Verify agent responds to issues
2. Confirm processing capabilities
3. Validate output format
4. Check error handling

### Test Data:
- Sample operation request
- Priority validation
- Label routing test
- Response time check

This is an automated test generated by the Agent Cross-Testing System.""",
            "labels": [{"name": label} for label in labels],
            "created_at": datetime.now().isoformat()
        }
    
    def run_agent_test(self, agent_script: str, test_issue: Dict[str, Any]) -> Tuple[bool, str]:
        """Run a single agent test"""
        # Save test issue to file
        issue_file = f"test_issue_{agent_script}.json"
        with open(issue_file, 'w') as f:
            json.dump(test_issue, f)
        
        try:
            # Run agent with test issue
            cmd = [
                sys.executable,
                f"{agent_script}.py",
                "--process-issue", str(test_issue["number"]),
                "--issue-data", issue_file
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            # Clean up test file
            os.remove(issue_file)
            
            # Check for success
            if result.returncode == 0:
                # Look for success indicators in output
                output = result.stdout.lower()
                if any(keyword in output for keyword in ["processing", "loaded", "completed", "analysis"]):
                    return True, result.stdout[:500]
                else:
                    return False, f"No processing indicators found: {result.stdout[:500]}"
            else:
                return False, f"Error: {result.stderr[:500]}"
                
        except subprocess.TimeoutExpired:
            return False, "Agent timeout (30s)"
        except Exception as e:
            return False, f"Exception: {str(e)}"
        finally:
            # Ensure cleanup
            if Path(issue_file).exists():
                os.remove(issue_file)
    
    def test_agent_with_agent(self, tester: Tuple[str, str, List[str]], 
                             target: Tuple[str, str, List[str]]) -> Dict[str, Any]:
        """Have one agent test another agent"""
        tester_name, tester_desc, _ = tester
        target_name, target_desc, target_labels = target
        
        print(f"\n{'='*60}")
        print(f"CROSS-TEST: {tester_name} -> {target_name}")
        print(f"{'='*60}")
        
        # Create test issue for target agent
        test_issue = self.create_test_issue(tester_name, target_name, target_labels)
        
        # Run target agent with test issue
        success, output = self.run_agent_test(target_name, test_issue)
        
        # Store result
        result = {
            "tester": tester_name,
            "target": target_name,
            "success": success,
            "output": output,
            "timestamp": datetime.now().isoformat()
        }
        
        # Display result
        status = "[OK] PASS" if success else "[FAIL] FAIL"
        print(f"Result: {status}")
        if not success:
            print(f"Error: {output[:200]}")
        else:
            print(f"Output: {output[:200]}...")
        
        return result
    
    def run_comprehensive_testing(self):
        """Run comprehensive cross-testing matrix"""
        print("\n" + "="*80)
        print("AGENT CROSS-TESTING SYSTEM")
        print("="*80)
        print(f"Testing {len(self.agents)} agents in cross-validation matrix")
        
        total_tests = 0
        passed_tests = 0
        failed_tests = []
        
        # Each agent tests 3 other random agents
        import random
        
        for tester in self.agents:
            tester_name = tester[0]
            self.test_matrix[tester_name] = []
            
            # Select 3 other agents to test
            other_agents = [a for a in self.agents if a[0] != tester_name]
            targets = random.sample(other_agents, min(3, len(other_agents)))
            
            for target in targets:
                result = self.test_agent_with_agent(tester, target)
                self.test_matrix[tester_name].append(result)
                
                total_tests += 1
                if result["success"]:
                    passed_tests += 1
                else:
                    failed_tests.append(f"{tester_name} -> {target[0]}")
        
        # Generate report
        self.generate_test_report(total_tests, passed_tests, failed_tests)
    
    def test_critical_paths(self):
        """Test critical operational paths"""
        print("\n" + "="*80)
        print("CRITICAL PATH TESTING")
        print("="*80)
        
        critical_paths = [
            # P0 Security Issue Path
            {
                "name": "P0 Security Escalation",
                "agents": ["ai-security-agent", "ai-project-manager-agent", "ai-operations-agent"],
                "labels": ["security/compliance", "priority/P0", "management/escalation"]
            },
            # Financial Processing Path
            {
                "name": "Financial Analysis Pipeline",
                "agents": ["ai-finance-agent", "ai-analytics-agent", "ai-project-manager-agent"],
                "labels": ["finance/analysis", "analytics/reporting", "priority/P1"]
            },
            # Customer Issue Path
            {
                "name": "Customer Support Flow",
                "agents": ["ai-support-agent", "ai-customer-success-agent", "ai-analytics-agent"],
                "labels": ["support/quality-assurance", "success/user-research", "priority/P2"]
            },
            # Development Pipeline
            {
                "name": "Development Pipeline",
                "agents": ["ai-architect-agent", "ai-developer-agent", "ai-qa-agent", "ai-devops-agent"],
                "labels": ["system/design", "development/feature", "qa/testing", "priority/P2"]
            }
        ]
        
        for path in critical_paths:
            print(f"\nTesting: {path['name']}")
            print(f"Agents: {' -> '.join(path['agents'])}")
            
            # Create test issue
            test_issue = {
                "number": f"CRITICAL-{datetime.now().strftime('%H%M%S')}",
                "title": f"Critical Path Test: {path['name']}",
                "body": f"Testing critical path: {path['name']}",
                "labels": [{"name": label} for label in path['labels']]
            }
            
            # Test each agent in the path
            path_success = True
            for agent in path['agents']:
                success, output = self.run_agent_test(agent, test_issue)
                status = "[OK]" if success else "[FAIL]"
                print(f"  {agent}: {status}")
                if not success:
                    path_success = False
                    print(f"    Error: {output[:100]}")
            
            overall = "[OK] PATH SUCCESS" if path_success else "[FAIL] PATH FAILED"
            print(f"  Overall: {overall}")
    
    def test_coordinator_integration(self):
        """Test the policy coordinator with all agents"""
        print("\n" + "="*80)
        print("COORDINATOR INTEGRATION TEST")
        print("="*80)
        
        # Test coordinator can process issues
        print("Testing agent-policy-coordinator.py...")
        
        try:
            cmd = [sys.executable, "agent-policy-coordinator.py", "--once"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("[OK] Coordinator test passed")
                # Check if it found issues
                if "Found" in result.stdout and "issues" in result.stdout:
                    print(f"  Coordinator processed issues successfully")
            else:
                print("[FAIL] Coordinator test failed")
                print(f"  Error: {result.stderr[:200]}")
                
        except Exception as e:
            print(f"[FAIL] Coordinator test error: {e}")
    
    def generate_test_report(self, total: int, passed: int, failed_list: List[str]):
        """Generate comprehensive test report"""
        print("\n" + "="*80)
        print("TEST REPORT SUMMARY")
        print("="*80)
        
        pass_rate = (passed / total * 100) if total > 0 else 0
        
        print(f"Total Tests: {total}")
        print(f"Passed: {passed} ({pass_rate:.1f}%)")
        print(f"Failed: {total - passed}")
        
        if pass_rate >= 95:
            print(f"\n[OK] SYSTEM STATUS: EXCELLENT")
        elif pass_rate >= 80:
            print(f"\n⚠️ SYSTEM STATUS: GOOD (Minor Issues)")
        elif pass_rate >= 60:
            print(f"\n⚠️ SYSTEM STATUS: DEGRADED")
        else:
            print(f"\n[FAIL] SYSTEM STATUS: CRITICAL")
        
        if failed_list:
            print(f"\nFailed Tests:")
            for failure in failed_list:
                print(f"  - {failure}")
        
        # Save report to file
        report = {
            "timestamp": datetime.now().isoformat(),
            "total_tests": total,
            "passed": passed,
            "failed": total - passed,
            "pass_rate": pass_rate,
            "failed_tests": failed_list,
            "test_matrix": self.test_matrix
        }
        
        with open("agent_test_report.json", "w") as f:
            json.dump(report, f, indent=2)
        
        print(f"\nDetailed report saved to: agent_test_report.json")
    
    def test_individual_agent(self, agent_name: str):
        """Test a specific agent"""
        print(f"\n{'='*60}")
        print(f"TESTING: {agent_name}")
        print(f"{'='*60}")
        
        # Find agent details
        agent = None
        for a in self.agents:
            if a[0] == agent_name:
                agent = a
                break
        
        if not agent:
            print(f"[FAIL] Agent not found: {agent_name}")
            return
        
        # Create test issue
        test_issue = self.create_test_issue("test-system", agent_name, agent[2])
        
        # Run test
        success, output = self.run_agent_test(agent_name, test_issue)
        
        if success:
            print(f"[OK] {agent_name} test PASSED")
            print(f"Output: {output[:300]}...")
        else:
            print(f"[FAIL] {agent_name} test FAILED")
            print(f"Error: {output}")

def main():
    """Main testing orchestration"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Agent Cross-Testing System')
    parser.add_argument('--full', action='store_true', help='Run full cross-testing matrix')
    parser.add_argument('--critical', action='store_true', help='Test critical paths only')
    parser.add_argument('--coordinator', action='store_true', help='Test coordinator integration')
    parser.add_argument('--agent', type=str, help='Test specific agent')
    parser.add_argument('--quick', action='store_true', help='Quick test of all agents')
    args = parser.parse_args()
    
    tester = AgentCrossTester()
    
    if args.full:
        print("Running FULL cross-testing matrix...")
        tester.run_comprehensive_testing()
        tester.test_critical_paths()
        tester.test_coordinator_integration()
    elif args.critical:
        tester.test_critical_paths()
    elif args.coordinator:
        tester.test_coordinator_integration()
    elif args.agent:
        tester.test_individual_agent(args.agent)
    elif args.quick:
        print("Running quick test of all agents...")
        for agent in tester.agents:
            tester.test_individual_agent(agent[0])
    else:
        # Default: Run critical paths
        print("Running critical path testing (use --full for comprehensive tests)")
        tester.test_critical_paths()
        tester.test_coordinator_integration()

if __name__ == "__main__":
    main()